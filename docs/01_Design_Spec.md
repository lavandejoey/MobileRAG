# ä¸€ã€æ€»ä½“ç›®æ ‡ä¸è¾¹ç•Œ

* **å½¢æ€**ï¼šæœ¬åœ°ç¦»çº¿ä¼˜å…ˆçš„ Agentic RAG å¯¹è¯åº”ç”¨ï¼ˆChatbotï¼‰ï¼Œæ”¯æŒ CPU / GPUï¼ˆ6 GB æ˜¾å­˜ä¸ºä¾‹ï¼‰è‡ªåŠ¨åˆ‡æ¢ä¸æ‰‹åŠ¨æŒ‡å®šã€‚
* **è¯­ç§**ï¼šä¸­è‹± 1:1ï¼Œå…è®¸è·¨è¯­æ£€ç´¢ä¸è·¨è¯­å›ç­”ã€‚
* **å¤šæ¨¡æ€**ï¼šæ–‡æœ¬ + å›¾ç‰‡ã€‚
* **æ ¸å¿ƒæ•°æ®æ¥æº**ï¼šæ–‡ä»¶ä¸å›¾ç‰‡ï¼ˆæœ¬åœ°ï¼‰ï¼Œå¯¹è¯å†å²åªåšâ€œå¯å­˜å¯è°ƒâ€è€Œéä¸»è¦çŸ¥è¯†æºã€‚
* **è¾“å‡ºç¡¬çº¦æŸ**ï¼šæ¯æ¬¡å›ç­”**å¿…é¡»**å¸¦â€œè¯æ®é“¾æ¥â€ï¼ˆæœ¬åœ°æ–‡ä»¶è·¯å¾„/é¡µç ã€å›¾ç‰‡è·¯å¾„ç­‰ï¼‰ã€‚
* **æŒä¹…åŒ–**ï¼šå‘é‡åº“æœ¬åœ°æŒä¹…åŒ–ï¼›ç¦»çº¿**å¢é‡æ›´æ–°**ï¼ˆæ–°å¢/ä¿®æ”¹/åˆ é™¤æ£€æµ‹ï¼‰å¯ç¨³å®šè¿è¡Œã€‚
* **å¤æ‚åº¦æ§åˆ¶**ï¼šLangGraph è´Ÿè´£ç¼–æ’ä¸çŠ¶æ€æŒä¹…åŒ–ï¼ˆSQLite checkpointerï¼‰ï¼›LangChain
  å®Œæˆæ¨¡å‹ä¸å‘é‡åº“é€‚é…ã€‚([LangChain AI][1], [LangChain Blog][2])

---

# äºŒã€æ¨¡å‹ä¸å‘é‡åº“é€‰å‹

## ç”Ÿæˆï¼ˆLLMï¼‰

* **Qwen3-1.7B-Base**ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ **32 K**ï¼ˆæœ¬åœ°é‡åŒ–å¯è¿è¡Œï¼‰ã€‚([Hugging Face][3], [Qwen][4])

## æ–‡æœ¬åµŒå…¥ï¼ˆDenseï¼‰

* **Qwen3-Embedding-0.6B**ï¼Œå¤šè¯­ã€**Instruction-aware**ï¼Œæ”¯æŒ **MRLï¼ˆå¯å˜ç»´åº¦ï¼‰**ï¼›æˆ‘ä»¬ç»Ÿä¸€é‡‡ç”¨ 1024 ç»´ï¼ˆä¾¿äºåº“å»ºæ¨¡ï¼‰ã€‚å¯ç”¨
  TEIï¼ˆText Embeddings Inferenceï¼‰CPU/GPU æœåŠ¡åŒ–æˆ–æœ¬åœ° Transformers æ¨ç†ã€‚([Hugging Face][5], [GitHub][6], [arXiv][7])

## æ–‡æœ¬é‡æ’ï¼ˆCross-Encoderï¼‰

* **Qwen3-Reranker-0.6Bï¼ˆsequence-classification å˜ä½“ï¼‰**ï¼ŒTopKâ‰ˆ80â†’TopRâ‰ˆ8â€“12ï¼›è¯¥åºåˆ—åˆ†ç±»æ”¹é€ ç‰ˆç”¨äºé«˜æ•ˆæ‰“åˆ†ï¼Œé¿å…ç”Ÿæˆå¼ logits
  æ…¢çš„é—®é¢˜ã€‚([Hugging Face][8])

## å›¾åƒå‘é‡ï¼ˆDenseï¼Œè·¨æ¨¡æ€ï¼‰

* **OpenCLIP ViT-B/32ï¼ˆLAION2Bï¼‰**ï¼šæ–‡æœ¬ä¸å›¾åƒå…±äº«åµŒå…¥ç©ºé—´ï¼Œæ”¯æŒ textâ†”image æ£€ç´¢ã€‚([GitHub][9], [Hugging Face][10])

## å›¾ç‰‡è‡ªåŠ¨ Caption

* **BLIP image-captioning-base**ï¼ˆTransformers åŸç”Ÿæ”¯æŒï¼›ä¹Ÿæœ‰è½»é‡é‡åŒ–å˜ä½“å¯é€‰ï¼‰ã€‚Caption
  é»˜è®¤è‹±æ–‡ï¼Œå…¥åº“åšç¨€ç–/ç¨ å¯†èåˆã€‚([Hugging Face][11])

## å‘é‡æ•°æ®åº“

* **Qdrantï¼ˆæœ¬åœ°æ¨¡å¼ / on-diskï¼‰**ï¼š

    * **Local mode** æ”¯æŒå†…å­˜æˆ–ç£ç›˜æŒä¹…åŒ–ï¼Œæ— éœ€ç‹¬ç«‹æœåŠ¡ï¼ˆä¹Ÿå¯éšæ—¶åˆ‡æ¢ Docker
      æœåŠ¡ç‰ˆï¼‰ã€‚([LangChain][12], [qdrant.tech][13], [Haystack][14])
    * **Named Vectors**ï¼šåŒä¸€ point æŒå¤šç§å‘é‡ï¼ˆä¾‹å¦‚ `text_dense`ã€`image`ã€`text_sparse`
      ï¼‰ï¼Œå…è®¸æœ‰çš„ç‚¹åªå­˜å…¶ä¸€ã€‚([qdrant.tech][15])
    * **Sparse/Hybrid**ï¼šç¨€ç–å‘é‡ä¸€ç­‰å…¬æ°‘ï¼Œå†…ç½® **Hybrid Query**
      ï¼ˆç¨ å¯†+ç¨€ç–æœåŠ¡ç«¯èåˆï¼‰ï¼Œå®˜æ–¹æœ‰æ··åˆæ£€ç´¢ä¸é‡æ’æ•™ç¨‹ã€‚([qdrant.tech][16])
    * **å­˜å‚¨**ï¼šæ”¯æŒ in-memory ä¸ on-disk payloadï¼ŒRocksDB é©±åŠ¨ï¼Œåˆ©äºå¤§ payloadï¼›å¯å»ºç´¢å¼•ä¼˜åŒ–è¿‡æ»¤ã€‚([qdrant.tech][17])

---

# ä¸‰ã€æ•°æ®ä¸é›†åˆè®¾è®¡ï¼ˆQdrantï¼‰

## Collectionï¼š`rag_multimodal`

* **named vectors**

    * `text_dense`ï¼šsize=1024ï¼Œdistance=cosineï¼ˆQwen3-Embeddingï¼‰ã€‚
    * `image`ï¼šsize=512ï¼Œdistance=cosineï¼ˆOpenCLIPï¼‰ã€‚
    * `text_sparse`ï¼šç¨€ç–å‘é‡ï¼ˆBM25/SPLADE++ï¼ŒQdrant åŸç”Ÿå­˜å‚¨ï¼‰ã€‚([qdrant.tech][15])
* **payloadï¼ˆå…ƒæ•°æ®ï¼‰**

    * `doc_id`, `chunk_id`, `file_path`, `title`, `lang`, `page`, `bbox`,
    * `version`, `sha256`, `mtime`, `phash`(å›¾åƒ), `modality` âˆˆ {text,image},
    * `caption`ï¼ˆBLIP è‹±æ–‡æè¿°ï¼Œå¯é€‰ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚

> è¯´æ˜ï¼šQdrant å…è®¸æŸä¸ª point åªæºå¸¦å…¶æ‹¥æœ‰çš„å‘é‡ï¼ˆå¦‚å›¾ç‰‡ä»…æœ‰ `image`
> å‘é‡ï¼‰ï¼Œè¿™éå¸¸é€‚åˆâ€œæ–‡æœ¬+å›¾ç‰‡â€åŒåº“ç®¡ç†ã€‚([qdrant.tech][18])

---

# å››ã€ç¦»çº¿â€œå¢é‡æ›´æ–°â€æµæ°´çº¿ï¼ˆScan â†’ Chunk â†’ Embed â†’ Upsertï¼‰

1. **æ‰«æ**ï¼šéå†æ–‡ä»¶/å›¾ç‰‡ï¼Œè®¡ç®— `sha256` + `mtime`ï¼ˆå›¾ç‰‡è¿˜ç®— `pHash`ï¼‰ï¼›å†³å®šæ–°å¢/æ›´æ–°/è½¯åˆ ã€‚
2. **åˆ‡ç‰‡**ï¼š

    * æ–‡æœ¬/PDFï¼šç”¨ **Unstructured**ï¼ˆ`auto/hi_res/ocr_only` è‡ªé€‚åº”ï¼‰+ **PyMuPDF** è·å–é¡µç /å—ä¸å¯é€‰
      `bbox`ã€‚([docs.unstructured.io][19], [pymupdf.readthedocs.io][20])
3. **å‘é‡åŒ–**ï¼š

    * æ–‡æœ¬ Denseï¼šQwen3-Embedding-0.6Bï¼ˆæ–‡æ¡£ç”¨é»˜è®¤æŒ‡ä»¤ï¼›æŸ¥è¯¢ä¾§å¯ç”¨ **instruction-aware** æ¨¡æ¿ï¼‰ã€‚([Hugging Face][5])
    * ç¨€ç–ï¼š**FastEmbed** ç”Ÿäº§ BM25 / SPLADE++
      ç¨€ç–å‘é‡ï¼ˆæ— å¤–éƒ¨æœåŠ¡ï¼‰ã€‚([GitHub][21], [qdrant.tech][22], [qdrant.github.io][23])
    * å›¾ç‰‡ Denseï¼šOpenCLIPï¼›å¹¶ç”¨ BLIP ç”Ÿæˆ `caption` å…¥åº“ã€‚([GitHub][9], [Hugging Face][11])
4. **Upsert**ï¼šä¸»é”® `doc_id#chunk_id#version` å¹‚ç­‰å†™å…¥ï¼›æ—§ç‰ˆæœ¬è½¯åˆ ä»¥æ”¯æŒå›æ»šã€‚

---

# äº”ã€æ£€ç´¢ä¸é‡æ’ï¼ˆHybridâ†’Rerankï¼‰

* **Hybrid æ£€ç´¢ï¼ˆQdrantï¼‰**ï¼š

    * æ–‡æœ¬æŸ¥è¯¢ï¼šdense(`text_dense`) + sparse(`text_sparse`) èåˆï¼›
    * å›¾åƒ/è·¨æ¨¡æ€ï¼šdense(`image`) ä¸æ–‡æœ¬ caption æ··åˆï¼›
    * è¿‡æ»¤ï¼šæŒ‰ `modality/lang/time_range` ç­‰ payloadã€‚([qdrant.tech][16])
* **é‡æ’**ï¼šQwen3-Reranker-0.6B seq-clsï¼Œå¯¹ TopKâ‰ˆ80 å€™é€‰é‡æ’ï¼Œå– 8â€“12 è¿›å…¥ LLM ä¸Šä¸‹æ–‡ã€‚([Hugging Face][8])

---

# å…­ã€å¯¹è¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰ä¸é•¿æœŸâ€œæŒä¹…è®°å¿†â€

## A) å¯¹è¯å†å²ï¼ˆSQLiteï¼‰

* **åŸå§‹æ—¥å¿—**ï¼š`chat_messages(id, session_id, role, ts, content, token_count, meta)`ã€‚
* **æ»šåŠ¨æ‘˜è¦**ï¼š`chat_summaries(session_id, upto_msg_id, summary_md, tokens)`ã€‚
* **ç­–ç•¥**ï¼šå½“å†å² > \~1800 tokens æˆ–æ¯ 5â€“8 è½®è§¦å‘â€œ**æ»šåŠ¨å‹ç¼©**â€ï¼›è¿‘é‚»é€‰æ‹©ä¿ç•™æœ€è¿‘ 8 è½®é‡Œâ€œé«˜ä¿¡æ¯å¯†åº¦â€ç‰‡æ®µï¼Œå¿…è¦æ—¶åšå¥çº§æ‘˜è¦ã€‚
* **æŠ•å–‚é¡ºåº**ï¼š`Conversation summary`ï¼ˆâ‰¤600ï¼‰â†’ `Recent turns`ï¼ˆâ‰¤400ï¼‰ã€‚

## B) é•¿æœŸè®°å¿†ï¼ˆQdrant å°é›†åˆ + SQLite ç´¢å¼•ï¼‰

* **é›†åˆ**ï¼š`agent_memory`ï¼ˆ`text_dense` + `text_sparse`ï¼‰ã€‚
* **å­—æ®µ**ï¼š`kind(profile|preference|fact|project)`, `statement`, `tags[]`, `source_session/msg_ids`, `confidence`,
  `ttl/null`, `decay_score`ã€‚
* **æ£€ç´¢**ï¼šç”¨â€œå½“å‰é—®é¢˜ + ä¸»é¢˜å…³é”®è¯â€æŸ¥è¯¢ï¼ŒHybrid å¬å› Top-5ï¼ˆæ€» â‰¤250 tokensï¼‰ã€‚
* **è®°å¿†é—¨ï¼ˆmemory\_gateï¼‰**ï¼š

    * è§„åˆ™ä¼˜å…ˆï¼ˆâ€œä»ç°åœ¨å¼€å§‹/ä»¥åéƒ½â€¦â€ç­‰ï¼‰ï¼›
    * è½»é‡åˆ†ç±»ï¼ˆé•¿æœŸæ€§ã€å¯éªŒè¯ã€æ— æ˜ç¡®æ—¶æ•ˆï¼‰å…¨æ»¡è¶³æ‰å…¥åº“ï¼›
    * å»é‡åˆå¹¶ + è¡°å‡å†·è—ï¼ˆé•¿æœŸæœªå‘½ä¸­é™ä½ `decay_score`ï¼‰ã€‚

> è¯­è¨€æ£€æµ‹ç”¨ **fastText lid.176**ï¼ˆ176 è¯­ç§ï¼Œè½»é‡å¯é ï¼‰ï¼›éœ€è¦æ—¶å¯åˆ‡ Linguaã€‚([fasttext.cc][24])

---

# ä¸ƒã€ä¸Šä¸‹æ–‡æ‹¼è£…ä¸ Token é¢„ç®—ï¼ˆä¸è½»æ˜“è£å‰ªï¼Œå…ˆèªæ˜å‹ç¼©ï¼‰

* **å»ºè®®é¢„ç®—ï¼ˆå¯åŠ¨æ€è°ƒèŠ‚ï¼‰**

    * ç³»ç»Ÿ/å·¥å…·æŒ‡ä»¤ â‰¤ 400
    * çŸ­æœŸè®°å¿†ï¼ˆæ‘˜è¦+è¿‘é‚»ï¼‰â‰¤ 1 000
    * é•¿æœŸè®°å¿† â‰¤ 250
    * è¯æ®ä¸Šä¸‹æ–‡ â‰¤ 2 200
    * å®‰å…¨ç¼“å†² â‰¥ 150
* **åŠ¨æ€ç®—æ³•**ï¼šå…ˆæŒ‰ä¿¡æ¯ä»·å€¼åˆ†é…é…é¢â†’å»å†—ä½™â†’å¥çº§/æ®µçº§æ‘˜è¦â†’æ‘˜è¦å†æ‘˜è¦â†’**æœ€å**æ‰æŒ‰æ—¶é—´æ·˜æ±°æœ€è€è¿‘é‚»ã€‚

---

# å…«ã€è®¾å¤‡è‡ªé€‚åº”ä¸é‡åŒ–

* **ä¼˜å…ˆçº§**ï¼šGPU â†’ **é‡æ’ + ç”Ÿæˆ**ï¼›åµŒå…¥å¯ CPU æ‰¹å¤„ç†ï¼ŒGPU ç©ºé—²å†è¿ç§»ã€‚
* **Transformers è·¯çº¿**ï¼š`bitsandbytes` **8-bit/4-bit** é‡åŒ– + `device_map="auto"`ï¼ˆè‡ªåŠ¨æŠŠæƒé‡åˆ†é…åˆ°å¯ç”¨ GPU/CPU/ç£ç›˜ï¼‰ï¼ŒOOM
  è‡ªåŠ¨é™æ‰¹/é™ç²¾åº¦/åˆ‡ CPUã€‚([Hugging Face][25])
* **Embedding æœåŠ¡åŒ–ï¼ˆå¯é€‰ï¼‰**ï¼šHugging Face **TEI** æ”¯æŒ **Qwen3-Embedding-0.6B**ï¼ŒCPU/GPU
  çš†å¯è¿è¡Œã€‚([GitHub][26], [Hugging Face][27])

---

# ä¹ã€æ£€ç´¢/ç”Ÿæˆå‚æ•°

* **åˆ‡ç‰‡**ï¼šæ¯å— 640 tokensï¼Œoverlap 128ã€‚
* **æ£€ç´¢**ï¼š`dense_k=60`ï¼Œ`sparse_k=60`ï¼ŒHybrid æƒé‡ Î»=0.5 èµ·æ­¥ï¼ˆç”¨éªŒè¯é›†å†è°ƒï¼‰ã€‚([qdrant.tech][16])
* **å›¾åƒæ£€ç´¢**ï¼š`image_k=40`ã€‚
* **é‡æ’**ï¼š`TopK_in=80 â†’ TopR=10`ã€‚
* **ç­”å¤è¯­è¨€**ï¼šè·Ÿéšç”¨æˆ·è¾“å…¥è¯­ç§ï¼›è·¨è¯­é—®é¢˜ä¿ç•™åŸæ–‡è¯æ® + ç›®æ ‡è¯­æ‘˜è¦ã€‚
* **åµŒå…¥ç»´åº¦**ï¼š1024ï¼ˆä¸ `text_dense` ä¿æŒä¸€è‡´ï¼‰ã€‚

---

# åã€LangGraph æ‹“æ‰‘ï¼ˆå…³é”®èŠ‚ç‚¹ï¼‰

```
user_input
  â””â”€â–º device_resolver
      â””â”€â–º query_normaliser (å«è¯­è¨€æ£€æµ‹ / Qwen3 query æŒ‡ä»¤)
          â”œâ”€â–º history_loader + history_compactor (SQLite)
          â”œâ”€â–º memory_retriever (Qdrant agent_memory, hybrid)
          â”‚     â””â”€â–º memory_gate + memory_inserter (å¼‚æ­¥/å›åˆå)
          â”œâ”€â–º retriever_hybrid (Qdrant rag_multimodal)
          â”œâ”€â–º rerank (Qwen3-Reranker-0.6B seq-cls)
          â”œâ”€â–º budget_orchestrator (åŠ¨æ€å‹ç¼©/é…é¢)
          â””â”€â–º generator (Qwen3-1.7B)
                â””â”€â–º answer_with_citations (å¼ºåˆ¶è¯æ®é“¾æ¥)
```

* **æŒä¹…åŒ–**ï¼šLangGraph **SQLite checkpointer**
  ä¿å­˜æœ‰å‘å›¾çŠ¶æ€/çº¿ç¨‹ï¼ˆæ”¯æŒå›æ”¾/å®¹é”™/â€œè®°å¿†â€å¼èƒ½åŠ›ï¼‰ã€‚([LangChain AI][1], [PyPI][28])

---

# åä¸€ã€å¯¹è¯ä¸è¯æ®è¾“å‡ºè§„èŒƒ

* **Answer** æ­£æ–‡åé™„ **Evidence** åˆ—è¡¨ï¼š

    * æ–‡æœ¬ï¼š`[æ ‡é¢˜æˆ–æ–‡ä»¶å](file:///â€¦/paper.pdf#page=12) â€” ç‰‡æ®µæ‘˜è¦`
    * å›¾ç‰‡ï¼š`[img_00123.jpg](file:///â€¦/img/img_00123.jpg) â€” caption/ä½ç½®`
    * åŒæ–‡ä»¶å¤šç‰‡æ®µåˆå¹¶å±•ç¤ºï¼Œé¿å…åˆ·å±ã€‚
* è‹¥æ— è¶³å¤Ÿè¯æ®ï¼šæ˜ç¡®è¯´æ˜â€œæœªæ£€åˆ°æ”¯æŒæ€§è¯æ®â€ï¼Œå¹¶è¿”å›å¯å¤ç°çš„æ£€ç´¢å…³é”®è¯/è¿‡æ»¤æ¡ä»¶ã€‚

---

# åäºŒã€è¿è¡Œä¸è¿ç»´è¦ç‚¹

* **Qdrant æœ¬åœ°æ¨¡å¼**ï¼šå¯ `path=/your/db` è½ç›˜ï¼›éœ€è¦å‡çº§æ—¶æ¢ **Docker** æœåŠ¡ç‰ˆï¼ˆæŒ‚è½½ `/qdrant/storage`
  ï¼‰å³å¯ï¼Œæ•°æ®å¯è¿ç§»ã€‚([LangChain][12], [qdrant.tech][29])
* **ç¨€ç–/æ··åˆ**ï¼šFastEmbed ç”Ÿäº§ BM25/SPLADE++ï¼›Qdrant
  ç«¯ç›´æ¥èåˆåˆ†æ•°ï¼›å¿…è¦æ—¶åœ¨å®¢æˆ·ç«¯åšå½’ä¸€åŒ–/è°ƒæƒã€‚([GitHub][21], [qdrant.tech][22])
* **PDF/ç‰ˆé¢**ï¼šUnstructured `auto/hi_res/ocr_only` æŒ‰æ–‡ä»¶ç‰¹æ€§è‡ªé€‚åº”ï¼›PyMuPDF æå–æ–‡æœ¬å—/é¡µç /å¯é€‰
  bboxã€‚([docs.unstructured.io][19], [pymupdf.readthedocs.io][20])
* **è¯­è¨€æ£€æµ‹**ï¼šfastText lid.176ï¼ˆ176 è¯­ç§ï¼‰ï¼Œè½»é‡ã€æˆç†Ÿã€‚([fasttext.cc][24])
* **å¯è§‚æµ‹**ï¼šæœ€å°åŒ–æ—¥å¿—ï¼ˆSQLiteï¼‰è®°å½•ï¼šå¬å›/é‡æ’å¾—åˆ†ã€token é¢„ç®—ã€å†…å­˜å‘½ä¸­ä¸å†™å…¥ï¼›UI æä¾›â€œğŸ§  è®°å¿†æŠ½å±‰â€å®¡è®¡/ç¼–è¾‘ã€‚

---

# åä¸‰ã€å·²å¤„ç†çš„å…³é”®æƒè¡¡

* **åŒæºååŒ**ï¼šç”Ÿæˆ/åµŒå…¥/é‡æ’å‡é€‰ Qwen3 å®¶æ—ï¼Œè¯­è¨€ä¸é£æ ¼ä¸€è‡´ï¼›åŒæ—¶ç”¨ OpenCLIP
  è§£å†³è·¨æ¨¡æ€æ£€ç´¢ã€‚([Qwen][30], [Hugging Face][10])
* **ç®€æ´ vs èƒ½åŠ›**ï¼šQdrant çš„ **Local mode + Named Vectors + Hybrid**
  åœ¨â€œæ–‡æœ¬+å›¾ç‰‡+æ··åˆæ£€ç´¢+ç¦»çº¿å¢é‡â€ä¸Šä¸€æ¬¡åˆ°ä½ï¼Œé¿å…å¤šåº“/å¤šè¿›ç¨‹å¤æ‚æ€§ã€‚([qdrant.tech][13])
* **æ€§èƒ½ vs èµ„æº**ï¼šGPU ä¼˜å…ˆé‡æ’/ç”Ÿæˆï¼›åµŒå…¥æ‰¹å¤„ç†å¯ CPU è·‘ï¼›å¿…è¦æ—¶ä»¥ bitsandbytes + device\_map
  è‡ªåŠ¨åˆ†é…æƒé‡ã€‚([Hugging Face][25])
* **Token æˆæœ¬**ï¼šçŸ­æœŸå†å²æ»šåŠ¨æ‘˜è¦ + è¿‘é‚»æ‘˜å½•ï¼›é•¿æœŸè®°å¿†å°é›†åˆæ£€ç´¢ï¼›â€œå…ˆå‹ç¼©åè£å‰ªâ€ï¼Œæœ€å¤§åŒ–æœ‰æ•ˆä¿¡æ¯ã€‚

---

# åå››ã€è¡¥å……ï¼šæç®€é…ç½®è‰æ¡ˆï¼ˆæ‘˜ï¼‰

```yaml
app:
  device: auto      # auto / cpu / cuda:0
models:
  generator: Qwen/Qwen3-1.7B-Base
  embed_text: Qwen/Qwen3-Embedding-0.6B
  reranker: tomaarsen/Qwen3-Reranker-0.6B-seq-cls
  clip_image: laion/CLIP-ViT-B-32-laion2B-s34B-b79K
  captioner: Salesforce/blip-image-captioning-base
vectorstore:
  kind: qdrant_local
  path: ./qdrant_db
  collection: rag_multimodal
  named_vectors:
    text_dense: { size: 1024, distance: cosine }
    image: { size: 512, distance: cosine }
    text_sparse: { sparse: true }
retrieval:
  dense_k: 60
  sparse_k: 60
  hybrid_lambda: 0.5
  image_k: 40
  rerank_topk: 80
  rerank_topr: 10
ingest:
  text_chunk_tokens: 640
  text_chunk_overlap: 128
  caption_lang: en
output:
  require_citations: true
```

---

# å‚è€ƒé“¾æ¥

* **LangGraph æŒä¹…åŒ– / SQLite checkpointer**ï¼šå®˜æ–¹æ¦‚å¿µä¸å‘å¸ƒè¯´æ˜ã€‚([LangChain AI][1], [LangChain Blog][2])
* **Qwen3-1.7B-Base åŠ 32K ä¸Šä¸‹æ–‡**ï¼šæ¨¡å‹å¡ & å®˜æ–¹åšå®¢ã€‚([Hugging Face][3], [Qwen][4])
* **Qwen3-Embeddingï¼ˆ0.6Bï¼›MRLï¼›Instruction-awareï¼‰**ï¼šæ¨¡å‹å¡/ä»“åº“/è®ºæ–‡ï¼›TEI
  éƒ¨ç½²æ–‡æ¡£ã€‚([Hugging Face][5], [GitHub][6], [arXiv][7])
* **Qwen3-Reranker åºåˆ—åˆ†ç±»å˜ä½“**ï¼šHugging Face æ¨¡å‹é¡µã€‚([Hugging Face][8])
* **OpenCLIP ViT-B/32**ï¼šä»“åº“ä¸æ¨¡å‹å¡ã€‚([GitHub][9], [Hugging Face][31])
* **BLIP Caption æ¨¡å‹ä¸ç”¨æ³•**ï¼šæ¨¡å‹å¡ä¸ Transformers æ–‡æ¡£ã€‚([Hugging Face][11])
* **Qdrantï¼šNamed Vectors / Sparse / Hybrid**ï¼šæ¦‚å¿µæ–‡æ¡£ã€Hybrid Queriesã€Points è¯´æ˜ã€‚([qdrant.tech][15])
* **Qdrantï¼šLocal modeï¼ˆå†…å­˜/ç£ç›˜ï¼‰ä¸æœ¬åœ°è½ç›˜ç¤ºä¾‹**ï¼šLangChain é›†æˆæ–‡æ¡£ä¸ Qdrant æŒ‡å—ã€‚([LangChain][12], [qdrant.tech][13])
* **Qdrantï¼šå­˜å‚¨ç­–ç•¥ï¼ˆInMemory/OnDisk/RocksDBï¼‰**ã€‚([qdrant.tech][17])
* **FastEmbedï¼ˆBM25/SPLADE++ ç¨€ç–ï¼‰**ï¼šå®˜æ–¹ä¸æ•™ç¨‹ã€‚([GitHub][21], [qdrant.tech][22], [qdrant.github.io][23])
* **Unstructured / PyMuPDF**ï¼šåˆ†åŒºç­–ç•¥ä¸æ–‡æœ¬/é¡µç /å—æå–ã€‚([docs.unstructured.io][19], [pymupdf.readthedocs.io][20])
* **è¯­è¨€è¯†åˆ« fastText lid.176**ï¼šå®˜æ–¹æ–‡æ¡£ã€‚([fasttext.cc][24])
* **Bitsandbytes é‡åŒ–ä¸ device\_map='auto'**ï¼šTransformers/Accelerate æ–‡æ¡£ã€‚([Hugging Face][25])

[1]: https://langchain-ai.github.io/langgraph/concepts/persistence/?utm_source=chatgpt.com "LangGraph persistence - GitHub Pages"

[2]: https://blog.langchain.com/langgraph-v0-2/?utm_source=chatgpt.com "LangGraph v0.2: Increased customization with new ..."

[3]: https://huggingface.co/Qwen/Qwen3-1.7B-Base?utm_source=chatgpt.com "Qwen/Qwen3-1.7B-Base"

[4]: https://qwenlm.github.io/blog/qwen3/?utm_source=chatgpt.com "Qwen3: Think Deeper, Act Faster | Qwen"

[5]: https://huggingface.co/Qwen/Qwen3-Embedding-0.6B?utm_source=chatgpt.com "Qwen/Qwen3-Embedding-0.6B"

[6]: https://github.com/QwenLM/Qwen3-Embedding?utm_source=chatgpt.com "QwenLM/Qwen3-Embedding"

[7]: https://arxiv.org/pdf/2506.05176?utm_source=chatgpt.com "Qwen3 Embedding: Advancing Text Embedding and ..."

[8]: https://huggingface.co/tomaarsen/Qwen3-Reranker-0.6B-seq-cls?utm_source=chatgpt.com "tomaarsen/Qwen3-Reranker-0.6B-seq-cls"

[9]: https://github.com/mlfoundations/open_clip?utm_source=chatgpt.com "mlfoundations/open_clip: An open source implementation ..."

[10]: https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K?utm_source=chatgpt.com "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"

[11]: https://huggingface.co/Salesforce/blip-image-captioning-base?utm_source=chatgpt.com "Salesforce/blip-image-captioning-base"

[12]: https://python.langchain.com/docs/integrations/vectorstores/qdrant/?utm_source=chatgpt.com "Qdrant"

[13]: https://qdrant.tech/documentation/frameworks/langchain/?utm_source=chatgpt.com "Langchain"

[14]: https://haystack.deepset.ai/integrations/qdrant-document-store?utm_source=chatgpt.com "Qdrant - Haystack - Deepset"

[15]: https://qdrant.tech/documentation/concepts/collections/?utm_source=chatgpt.com "Collections"

[16]: https://qdrant.tech/documentation/concepts/hybrid-queries/?utm_source=chatgpt.com "Hybrid Queries"

[17]: https://qdrant.tech/documentation/concepts/storage/?utm_source=chatgpt.com "Storage"

[18]: https://qdrant.tech/documentation/concepts/points/?utm_source=chatgpt.com "Points"

[19]: https://docs.unstructured.io/open-source/core-functionality/partitioning?utm_source=chatgpt.com "Partitioning"

[20]: https://pymupdf.readthedocs.io/en/latest/recipes-text.html?utm_source=chatgpt.com "Text - PyMuPDF 1.26.3 documentation"

[21]: https://github.com/qdrant/fastembed?utm_source=chatgpt.com "qdrant/fastembed: Fast, Accurate, Lightweight Python ..."

[22]: https://qdrant.tech/documentation/fastembed/fastembed-splade/?utm_source=chatgpt.com "Working with SPLADE"

[23]: https://qdrant.github.io/fastembed/examples/SPLADE_with_FastEmbed/?utm_source=chatgpt.com "SPLADE with FastEmbed"

[24]: https://fasttext.cc/docs/en/language-identification.html?utm_source=chatgpt.com "Language identification"

[25]: https://huggingface.co/docs/transformers/en/quantization/bitsandbytes?utm_source=chatgpt.com "Bitsandbytes"

[26]: https://github.com/huggingface/text-embeddings-inference?utm_source=chatgpt.com "huggingface/text-embeddings-inference: A blazing fast ..."

[27]: https://huggingface.co/docs/text-embeddings-inference/en/local_cpu?utm_source=chatgpt.com "Using TEI locally with CPU"

[28]: https://pypi.org/project/langgraph-checkpoint-sqlite/?utm_source=chatgpt.com "langgraph-checkpoint-sqlite"

[29]: https://qdrant.tech/documentation/quickstart/?utm_source=chatgpt.com "Local Quickstart"

[30]: https://qwenlm.github.io/blog/qwen3-embedding/?utm_source=chatgpt.com "Advancing Text Embedding and Reranking Through ... - Qwen"

[31]: https://huggingface.co/laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k?utm_source=chatgpt.com "laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k"
